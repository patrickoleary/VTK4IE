
There is a growing body of evidence demonstrating measurable benefits
attained when exploring scientific data using immersive interfaces.
Molecular research at UNC~\cite{Brooks:1990},
genetics at NCSA~\cite{Brady:1995},
oil well placement at the University of Colorado~\cite{Gruchalla:2004},  confocal microscopy data at Brown University~\cite{Prabhat:2008}, and interdisciplinary immersive visual analytics at the Electronic Visualization Laboratory~\cite{Marai:2016} to name but a few.
We know too that while not scientifically verifiable, any time a scientist
expresses a case where they "discovered" some relationship in their data
while immersed in a virtual reality system, we can make the case that the
interface provided a utility that helped them advance their work.

Yet, knowing that there are benefits is only half the equation.
The other half is the cost.
And a considerable contribution to the cost | one that is often not
formulated | is personnel time to get data into the VR system.
That time expense is often exacerbated due to a lack of tools that
allow data to be directly imbibed into a virtual environment.

A path that many research teams have taken is to use the established and
feature-rich Visualization ToolKit (VTK).
VTK is a programming-level API that provides quick access to an expanse
of scientific visualization rendering algorithms, as well as components
for displaying and interacting with the results on a desktop display.
However, while the concept of combining VTK with VR was sound, the
compatibility of VTK with other rendering software presented a difficult
challenge.  
There were several reasonably successful attempts at this amalgamation,
but in the end, there were either too many inefficiencies to allow the
software to be adequately interactive, or the melding was too fragile to
maintain as VTK and the VR libraries each evolved.

Consequently, the better solution was to adapt VTK to enable it to be
more easily integrated into other rendering systems.
Thus we adapted VTK by adding new options for rendering.
Rather than always rendering into windows with graphics contexts
created by VTK itself, there is now the option to "externally" render
into contexts provide by a collaborating system, or even integrate a
VR system directly into VTK.


Immersive visualization efforts are often associated with research
facilities that provide large-scale VR systems such as CAVEs\texttrademark and
other large-screen walk-in displays.
There is also a growing audience of potential VR users who can now
gain access to immersive interfaces through the new abundance and low-cost
of head-mounted displays (HMDs).
Ideally, there would be one solution to reach both audiences, and while
technically this is possible, the consumer systems offer a simpler
approach that will entice many devlopers to follow that path.
Thus we offer two approaches, one that addresses the simplier solution
of integrating directly with OpenVR, and other that allows integration
into any full-fledged VR integration library capable of interfacing
with CAVE-style and HMD displays.

\textbf{OpenGL context sharing}.
Our \texttt{vtkRenderingExternal} VTK module provides a complete integration API
including proper lighting, interaction, picking and access to the entire
VTK pipeline.
This, enables simple utilization for application developers using
any OpenGL-based VR Toolkit.

\textbf{VR Toolkit embedding}.
The OpenVR VTK module supports several immersive environments directly
without the issues faced by previous work, and is a complete template
for embedding other VR Toolkits within VTK in future work.

\textbf{Enhanced performance}.
As the nature of immersive interfaces, especially HMDs, requires
high-performance rendering, our effort also includes VTK rendering enhancements
These enhancements include:

\begin{compactitem}
\item A new default OpenGL 3.2+ pipeline;
\item dual depth peeling for transparency; and 
\item symmetric multiprocessing (SMP) tools and algorithms.
\end{compactitem}

Finally, we have exposed the framework of an image-based approach to the scientist through an advanced selection interface that allows them to make sophisticated (time, storage, analysis, ...) decisions for the production of \textit{in situ} visualization and analysis output.

In the sections that follow, we illustrate how our amalgamation of VTK and VR Toolkits support our goals for enhancing scientific visualization through immersive environments.

