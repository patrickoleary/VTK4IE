We would like to thank the reviewers for their insight, consideration and service. 

Our paper describes two new approaches to simplify the amalgamation of an immersive interface with visualization rendering from The visualization toolkit (VTK). In addition, we cover several enhancements to VTK that provide near real-time updates and efficient interaction. Finally, we demonstrate the combination of VTK with both Vrui and OpenVR/Oculus immersive environments in example applications.

We appreciate the time and consideration given our paper. The reviews provided a roadmap for improving our paper. We have done the three things asked for in the meta review, we added an Oculus update along side of the OpenVR work, and we also scoured the reviews to clean up other issues.

1. Add a paragraph in the related work, on how your proposed modules stand in contrast or supplements the following pieces of recent work:

   a. Moreland, K., Sewell, C., Usher, W., Lo, L. T., Meredith, J., Pugmire,
   D., ... & Larsen, M. (2016). VTK-m: Accelerating the Visualization
   Toolkit for Massively Threaded Architectures. IEEE Computer Graphics and
   Applications, 36(3), 48-58.

   At the end of the related work, we have added a new paragraph introducing VTK-m and the     roadmap for including VTK-m filters in VTK for use in immersive application development.

   b. Reda, K., Knoll, A., Nomura, K. I., Papka, M. E., Johnson, A. E., &
   Leigh, J. (2013, October). Visualizing large-scale atomistic simulations
   in ultra-resolution immersive environments. In LDAV (pp. 59-65).

   We added this citation to introductory paragraph of the related work section where we discussed exemplary scientific visualization virtual reality applications created from scratch using OpenGL.

   c. Hanwell, M. D., Martin, K. M., Chaudhary, A., & Avila, L. S. (2015).
   The Visualization Toolkit (VTK): Rewriting the rendering code for modern
   graphics cards. SoftwareX, 1, 9-12.

   In the second to last paragraph of the related work section, we highlighted the new OpenGl 3.2+ pipeline by Hanwell et al and described how we supplemented this work.

2. Remove all informal references to colloquial phrases such as \"bread and butter\" and \"under the hood\", and revise the language overall with a scholarly audience in mind. Correct all in-text references in place of all the \"?\" all through the manuscript. A general guideline is to save the final day to give a full proof-read through the penultimate pdf, and correct any obvious errors before re-submission.

   We have edited the entire paper and removed colloquial phrases. We have ran bibtex/latex and searched for “?” marks indicating missing citations and resolved those that were found. And we have give a full proof-read through the penultimate pdf.

3. In section 4.2.2, add more specifics to contrast your implementation to VRUI's 3D visualizer, and also to the Toirt Samhlaigh, explaining which is better in terms of ease of use and implementation, at basic and advanced levels of volume rendering, and why?

We added comparisons with other solutions for each of the examples at the end of the appropriate section.

GeometryViewer - This example has the functionality contained in the integration between Vrui and Delta3D presented in Sherman et al.[Sherman:2010]. Both applications were simple to develop, but GeometryViewer's  performance is faster especially when rendering transparent geometry. And GeometryViewer integrates the lighting between the VR toolkit and VTK in contrast to the Vrui/Delta3D integration, which requires modification the material textures to provide false lighting.

VolumeViewer - Immersive volume visualization applications are fundamental for a number of scientific research domains, and it's not surprising that there exists a number of partial solutions in the public domain. VolumeViewer has similar features contained in both 3D Visualizer[Billen:2008] and Toirt Samhlaigh[O’Leary:2008]. Both applications used complex, from scratch, OpenGL algorithms that were time consuming to develop. Visualizer uses a standard GPU GLSL shader-based raycasting algorithm. While Toirt uses a octree-based space skipping, GPU GLSL shader-based view-aligned algorithm to provide higher performance on larger volumes. In contrast, VolumeViewer required less than a hundred lines of VTK api to implement roughly the same GPU GLSL shader-based raycasting used in Visualizer. VolumeViewer's performance is equal to or exceeds the other tools. In addition, by modifying a line or two of VolumeViewer's code, it can accept data from any of the hundred plus supported scientific data formats a feat that would require the implementation of readers, data structures and algorithms in either of the other two applications.

MooseViewer - Like 3D Visualizer[Billen:2008], MooseViewer provides a number of scientific visualization techniques for simulation data, but MooseViewer was created in weeks with enhancements added by simply plugging in alternative VTK algorithms to enhance/scale performance.  Although focused on the ExodusII file format, accepting data from other scientific data formats in MooseViewer is a simple task. MooseViewer out performs Visualizer using VTK OpenGL 3.2+ rendering pipeline, but pure rendering performance fails to highlight Visualizer's unique immersive specific level-of-detail algorithms. 3DVisualizer is a fantastic immersive application, and, if an end-user has data in one of its accepted formats, we encourage end-users to leverage some of its unique features.

****
From the reviews
****

From Reviewer 3 - Also, in the first line of 3.1.2, explain what is meant by “the two rendering systems”.

To clarify the coordination requirement between the rendering systems, we replaced 

   “One of the most important prerequisites of this work was seamless stereo rendering and user interaction with the two rendering systems.”

with

   “One of the most important prerequisites of this work was seamless stereo rendering and user interaction between the rendering native to the base virtual reality toolkit and the rendering embedded in VTK.”

From Reviewer 2 - Related Work (Missing citations)

   Kuchera-Morin, JoAnn, et al. "Immersive full-surround multi-user system
   design." Computers & Graphics 40 (2014): 10-21.

We viewed this paper as hardware centric and decided to select the Amatriain, Xavier, et al. to cover the prior work of Allosphere and VTK.

   Amatriain, Xavier, et al. "The Allosphere: Immersive multimedia for
   scientific discovery and artistic exploration." IEEE MultiMedia 16.2
   (2009): 0064-75.

Citation added to the OpenGL context sharing subsection of the related work. Please note that as of October 2016 AlloSystem uses our vtkRenderingExternal VTK module presented in this paper.

   Febretti, Alessandro, et al. "Omegalib: A multi-view application
   framework for hybrid reality display environments." IEEE Virtual Reality
   (VR). IEEE, 2014.

Citation added to the OpenGL context sharing subsection of the related work.

   Marai, G. Elisabeta, Angus G. Forbes, and Andrew Johnson.
   "Interdisciplinary Immersive Analytics at the Electronic Visualization
   Laboratory: Lessons Learned and Upcoming Challenges." IEEE VR Workshop on
   Immersive Analytics. IEEE, 2016.

Citation added to the introductory section highlighting successful projects exploring scientific data using immersive interfaces.

   Reda, Khairi, et al. "Visualizing large, heterogeneous data in
   hybrid-reality environments." IEEE Computer Graphics and Applications
   33.4 (2013): 38-48.

This paper is broader than the one highlighted for inclusion Reda et al paper in the meta review. In this paper they do use the OmegaLib VTK plugin to show a lake’s bathysphere. We added this citation to introductory paragraph with the LDAV molecular dynamics visualization paper of the related work section where we discussed exemplary scientific visualization virtual reality applications created from scratch using OpenGL. We added the OmegaLib paper to the OpenGL context sharing subsection of the related work.