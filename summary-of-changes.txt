   1. Add a paragraph in the related work, on how your proposed modules
   stand in contrast or supplements the following pieces of recent work:

   a. Moreland, K., Sewell, C., Usher, W., Lo, L. T., Meredith, J., Pugmire,
   D., ... & Larsen, M. (2016). VTK-m: Accelerating the Visualization
   Toolkit for Massively Threaded Architectures. IEEE Computer Graphics and
   Applications, 36(3), 48-58.

At the end of the related work, we have added a new paragraph introducing VTK-m and the roadmap for including VTK-m filters in VTK for use in immersive application development.

   b. Reda, K., Knoll, A., Nomura, K. I., Papka, M. E., Johnson, A. E., &
   Leigh, J. (2013, October). Visualizing large-scale atomistic simulations
   in ultra-resolution immersive environments. In LDAV (pp. 59-65).

We added this citation to introductory paragraph of the related work section where we discussed exemplary scientific visualization virtual reality applications created from scratch using OpenGL.

   c. Hanwell, M. D., Martin, K. M., Chaudhary, A., & Avila, L. S. (2015).
   The Visualization Toolkit (VTK): Rewriting the rendering code for modern
   graphics cards. SoftwareX, 1, 9-12.

In the second to last paragraph of the related work section, we highlighted the new OpenGl 3.2+ pipeline by Hanwell et al and described how we supplemented this work.

   2. Remove all informal references to colloquial phrases such as \"bread
   and butter\" and \"under the hood\", and revise the language overall with
   a scholarly audience in mind. 

We have edited the entire paper and removed colloquial phrases.
“bread and butter” from 2 Related work section
“under the hood” from 3.3.3 vtkSMPTools

   Correct all in-text references in place of
   all the \"?\" all through the manuscript. A general guideline is to save
   the final day to give a full proof-read through the penultimate pdf, and
   correct any obvious errors before re-submission.

We have ran bibles and searched for “?” marks indicating missing citations and resolved those that were found.

   3. In section 4.2.2, add more specifics to contrast your implementation
   to VRUI's 3D visualizer, and also to the Toirt Samhlaigh, explaining
   which is better in terms of ease of use and implementation, at basic and
   advanced levels of volume rendering, and why?

We added comparisons with other solutions for each of the examples.

GeometryViewer - This example has the functionality contained in the integration between Vrui and Delta3D presented in Sherman et al.[Sherman:2010]. Both applications were simple to develop, but GeometryViewer's  performance is faster especially when rendering transparent geometry. And GeometryViewer integrates the lighting between the VR toolkit and VTK in contrast to the Vrui/Delta3D integration, which requires modification the material textures to provide false lighting.

VolumeViewer - Immersive volume visualization applications are fundamental for a number of scientific research domains, and it's not surprising that there exists a number of partial solutions in the public domain. VolumeViewer has similar features contained in both 3D Visualizer[Billen:2008] and Toirt Samhlaigh[O’Leary:2008]. Both applications used complex, from scratch, OpenGL algorithms that were time consuming to develop. Visualizer uses a standard GPU GLSL shader-based raycasting algorithm. While Toirt uses a octree-based space skipping, GPU GLSL shader-based view-aligned algorithm to provide higher performance on larger volumes. In contrast, VolumeViewer required less than a hundred lines of VTK api to implement roughly the same GPU GLSL shader-based raycasting used in Visualizer. VolumeViewer's performance is equal to or exceeds the other tools. In addition, by modifying a line or two of VolumeViewer's code, it can accept data from any of the hundred plus supported scientific data formats a feat that would require the implementation of readers, data structures and algorithms in either of the other two applications.

MooseViewer - Like 3D Visualizer[Billen:2008], MooseViewer provides a number of scientific visualization techniques for simulation data, but MooseViewer was created in weeks with enhancements added by simply plugging in alternative VTK algorithms to enhance/scale performance.  Although focused on the ExodusII file format, accepting data from other scientific data formats in MooseViewer is a simple task. MooseViewer out performs Visualizer using VTK OpenGL 3.2+ rendering pipeline, but pure rendering performance fails to highlight Visualizer's unique immersive specific level-of-detail algorithms. 3DVisualizer is a fantastic immersive application, and, if an end-user has data in one of its accepted formats, we encourage end-users to leverage some of its unique features.

From Reviewer 3 -

  Also, in the first line of 3.1.2, explain what is meant by “the two
   rendering systems”.

To clarify the coordination requirement between the rendering systems, we replaced 

   “One of the most important prerequisites of this work was seamless stereo rendering and user interaction with the two rendering systems.”

with

   “One of the most important prerequisites of this work was seamless stereo rendering and user interaction between the rendering native to the base virtual reality toolkit and the rendering embedded in VTK.”

From Reviewer 2

Related Work (Missing citations)

   Kuchera-Morin, JoAnn, et al. "Immersive full-surround multi-user system
   design." Computers & Graphics 40 (2014): 10-21.

We viewed this paper as hardware centric and decided to select the Amatriain, Xavier, et al. to cover the prior work of Allosphere and VTK.

   Amatriain, Xavier, et al. "The Allosphere: Immersive multimedia for
   scientific discovery and artistic exploration." IEEE MultiMedia 16.2
   (2009): 0064-75.

Citation added to the OpenGL context sharing subsection of the related work. Please note that as of October 2016 AlloSystem uses our vtkRenderingExternal VTK module presented in this paper.

   Febretti, Alessandro, et al. "Omegalib: A multi-view application
   framework for hybrid reality display environments." IEEE Virtual Reality
   (VR). IEEE, 2014.

Citation added to the OpenGL context sharing subsection of the related work.

   Marai, G. Elisabeta, Angus G. Forbes, and Andrew Johnson.
   "Interdisciplinary Immersive Analytics at the Electronic Visualization
   Laboratory: Lessons Learned and Upcoming Challenges." IEEE VR Workshop on
   Immersive Analytics. IEEE, 2016.

Citation added to the introductory section highlighting successful projects exploring scientific data using immersive interfaces.

   Reda, Khairi, et al. "Visualizing large, heterogeneous data in
   hybrid-reality environments." IEEE Computer Graphics and Applications
   33.4 (2013): 38-48.

This paper is broader than the one highlighted for inclusion Reda et al paper in the meta review. In this paper they do use the OmegaLib VTK plugin to show a lake’s bathysphere. We added this citation to introductory paragraph with the LDAV molecular dynamics visualization paper of the related work section where we discussed exemplary scientific visualization virtual reality applications created from scratch using OpenGL.We added the OmegaLib paper to the OpenGL context sharing subsection of the related work.

Rebuttal (We’ll remove this before we submit)

Overall Rating of the Submission

   1  (Definitely reject)

Justification of Recommendation

   It wasn't clear to me exactly what the contributions were. Other similar
   projects have been created in VR labs, such as UCSB's AlloSystem and
   UIC's OmegaLib, both of which enable the use of VTK in collaborative, VR
   environments, as well as on portable HMDs.

We have said that this has been done in the past in an ad hoc unmaintainable manner. We have added a citation to OmegaLib that relies on a plugin for VTK 5.10 (with an unfinished patch for VTK 6.1), and highlighted AlloSphere, which uses one of this papers VR environment VTK integrations (vtkRenderingExternal) as of Fall 2016.

   The authors focused on the
   simpler task of showing that their system worked in simple
   configurations, but I would have been more interested in hearing how the
   authors dealt with the complexities and/or minutia of specific
   environments. For instance, in systems with many screens,
   sharing+synchronizing GPUs +GL contexts needs to be handled, and in
   curved environments, blending of contexts is quite difficult, etc. 

This is done by the VR environment software the application developer chooses to work with (e.g. FreeVR, Vrui, VRJuggler, …).

   Even
   the proposed advantages of this system seem a bit dated. OIT and
   depth-peeling is nice, but not exactly novel, and although the system
   includes a GL 3.2+ rendering pipeline, there is nothing in the paper that
   explores GL 4.0 through 4.5 features, which could greatly enhance scivis
   tasks. 

In the recent past, perhaps the present for the VR community, when creating vr scientific visualization applications VTK may not have been a choice based on performance. We are updating the community on new and upcoming enhancements. VTK aims at supporting scientific visualization from mobile clients to immersive environments and compromises are often made.

   The inclusion of Vrui also seems useful, but again, there's
   nothing particularly novel about this as many VR frameworks (including
   ones that support VTK functionality) have similar UIs.

The VR environment VTK integration should work for all OpenGL or OpenVR environments. We created GLUT, FreeVR and Virus applications, but personally enjoy developing in Vrui.